# -*- coding: utf-8 -*-
"""Copy of model.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hINWSLXYAtraC5UZseM3S_G_bswWi6CZ
"""

import pandas as pd
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
import psycopg2
import sys
import json

data = json.loads(sys.argv[1])

# do something with the data
print(data['id'])


# establish connection to the database
conn = psycopg2.connect(
    host="localhost",
    database="major_project_db",
    user="postgres",
    password="root"
)

# create a cursor object
cur1 = conn.cursor()
# create a cursor object
cur2 = conn.cursor()

# execute the SQL query
cur1.execute("SELECT * FROM user_ratings")

# execute the SQL query
cur2.execute("SELECT * from courses_data order by course_id asc")

# fetch all the rows as a list of tuples
rows1 = cur1.fetchall()
# fetch all the rows as a list of tuples
rows2 = cur2.fetchall()

# close the cursor and database connection
cur1.close()
cur2.close()
conn.close()

# convert the list of tuples to a Pandas DataFrame
ratings_df = pd.DataFrame(rows1, columns=['user_id', 'course_id', 'ratings']) # replace with column names


# convert the list of tuples to a Pandas DataFrame
courses_df = pd.DataFrame(rows2, columns=['course_id', 'course_name', 'course_description', 'course_category', 'course_instructor', 'course_price', 'course_start_date', 'course_end_date', 'course_duration']) # replace with column names

#
# # Merge the course and ratings data
merged_df = pd.merge(courses_df, ratings_df, on='course_id')

# Pivot the merged data to create a user-item matrix
user_item_matrix = merged_df.pivot_table(index='user_id', columns='course_id', values='ratings')

# Fill missing values with 0
user_item_matrix.fillna(0, inplace=True)

# Compute the cosine similarity matrix
cosine_sim_matrix = cosine_similarity(user_item_matrix)

# Convert the cosine similarity matrix to a pandas DataFrame
cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=user_item_matrix.index, columns=user_item_matrix.index)

# Train the KNN model on the user-item matrix
model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(user_item_matrix)

# Function to recommend courses for a given user
def recommend_courses(user_id, num_recommendations, k):
    # Find the KNN of the user
    distances, indices = model_knn.kneighbors(user_item_matrix.loc[user_id].values.reshape(1, -1), n_neighbors=k+1)
    
    # Get the indices of the KNN
    knn_indices = indices.flatten()[1:]
    
    # Get the courses that the KNN have rated highly
    knn_ratings = user_item_matrix.loc[knn_indices]
    knn_ratings = knn_ratings[knn_ratings > 3].dropna(how='all')
    
    # Calculate the average rating for each course
    course_avg_ratings = knn_ratings.mean(axis=0)
    
    # Sort the courses by average rating and return the top recommendations
    top_courses = course_avg_ratings.sort_values(ascending=False)[:num_recommendations]
    recommended_course_ids = top_courses.index.tolist()
    recommended_courses = courses_df[courses_df['course_id'].isin(recommended_course_ids)]
    return recommended_courses

# Test the recommendation system for a given user
recommended_courses = recommend_courses(data['id'],8,2)
# print(recommended_courses)
# print(recommended_courses.to_string(columns=['course_id', 'course_name', 'course_description', 'course_category', 'course_instructor']))
# print(recommended_courses.course_id)
# print(recommended_courses.course_id.to_json())
# print(type(recommended_courses.course_id.to_json()))

outputData = json.loads(recommended_courses.course_id.to_json())
values = list(outputData.values())
print(values)
